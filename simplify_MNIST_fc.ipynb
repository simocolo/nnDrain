{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from nndrain.tensor_edit import TensorEdit\n",
    "from nndrain.simplify_linear import SimplifyLinear\n",
    "import nndrain.utils as utils\n",
    "\n",
    "utils.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with SimplifyLinear modules\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc = nn.ModuleList()\n",
    "\n",
    "        for i_l in range(len(hidden_size)+1):\n",
    "            in_size = 0\n",
    "            out_size = 0\n",
    "            if i_l==0:\n",
    "                in_size = input_size\n",
    "                out_size = hidden_size[0]\n",
    "                simplify_row = True\n",
    "                simplify_col = False\n",
    "                exclude_from_drain = True\n",
    "            elif i_l == len(hidden_size):\n",
    "                in_size = hidden_size[-1]\n",
    "                out_size = output_size\n",
    "                simplify_row = False\n",
    "                simplify_col = True\n",
    "                exclude_from_drain = False\n",
    "            else:\n",
    "                in_size = hidden_size[i_l-1]\n",
    "                out_size = hidden_size[i_l]\n",
    "                simplify_row = True\n",
    "                simplify_col = True\n",
    "                exclude_from_drain = False\n",
    "\n",
    "            sl = SimplifyLinear(in_size, out_size, simplify_row, simplify_col, min_row=10, min_col=10, exclude_from_drain=exclude_from_drain)\n",
    "            self.fc.append(sl)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        for i_l, l in enumerate(self.fc):\n",
    "            out = self.fc[i_l](out)\n",
    "            if i_l<len(self.fc)-1:\n",
    "                out = self.activation(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define net parameters and model\n",
    "input_size = 784\n",
    "hidden_size = [20000, 500, 50]\n",
    "num_classes = 10\n",
    "model = Net(input_size, hidden_size, num_classes).to(device)\n",
    "n_start_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "batch_size = 10\n",
    "num_epochs = 250\n",
    "fig = None\n",
    "train_accuracies = []\n",
    "train_losses = []\n",
    "\n",
    "filenames = []\n",
    "outdir = 'out/mnist/fc'\n",
    "isExist = os.path.exists(outdir)\n",
    "if not isExist:\n",
    "    os.makedirs(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "# Loss and optimizer\n",
    "lr = 1e-3\n",
    "lossFun = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# weights figure\n",
    "fig = plt.figure(figsize=(16, 10), facecolor='white')\n",
    "# select the layers that can be simplified\n",
    "simplify_layers = [module for module in model.modules() if isinstance(module, SimplifyLinear)]\n",
    "te = TensorEdit(simplify_layers)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    samples = 0\n",
    "    correct = 0\n",
    "\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # only for MSE Loss\n",
    "        #ones = torch.sparse.torch.eye(10).to(device)\n",
    "        #labels_ones = ones.index_select(0, labels)\n",
    "        loss = lossFun(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        samples += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # the force pulling down the weights in the range [-r_value; r_value] to zero\n",
    "        te.weights_drain(p_drain=0.005, threshold_coeff=3.0, condition=epoch!=0 and epoch%5==0)\n",
    "        # the following decay avoids getting stuck in the simplification process.\n",
    "        te.weights_decay(p_decay=0.01, decay_rate=5e-3, condition=epoch!=0 and epoch%2==0)\n",
    "        \n",
    "    # remove weights if all values ​​in a row or column are less than the specified value\n",
    "    if te.weights_remove(p_remove=1, threshold_coeff=0.5, max_removal=0.1, verbose=True):\n",
    "        # re-instantiate the optimizer with the new model if I have deleted any rows or columns\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "    # train loss, accuracy, number of parameters\n",
    "    train_accuracy = 100 * correct / samples\n",
    "    train_loss = total_loss / len(train_loader)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    train_losses.append(train_loss)\n",
    "    n_params = sum(p.numel() for p in model.parameters())\n",
    "    simplification = (1 - n_params / n_start_params) * 100\n",
    "\n",
    "    # test the model\n",
    "    model.eval()\n",
    "    test_accuracy = 0\n",
    "    test_dt = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        test_samples = 0\n",
    "        tnow = time.time()\n",
    "        for images, labels in test_loader:\n",
    "            images = images.reshape(-1, 28*28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_samples += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        test_dt = (time.time() - tnow) / test_samples\n",
    "        test_accuracy = 100 * correct / test_samples\n",
    "   \n",
    "    \n",
    "    # select the weight matrices transposing them for a better visualization\n",
    "    weights = [w.weight.data.T for w in simplify_layers]\n",
    "    title1 = \"MNIST Example Epoch [{}/{}] Train Loss: {:.4f} Params/StartParams: {}/{}\"\\\n",
    "                .format(epoch+1, num_epochs, loss.item(), n_params, n_start_params)\n",
    "    title2 = \"Linear Layer Weights Simplification: {:.1f}% Inference time: {:.2f}ms\"\\\n",
    "                .format(simplification, test_dt*1000)\n",
    "    title3 = \"Train Accuracy: {:.2f}% Test Accuracy: {:.2f}%\"\\\n",
    "                .format(train_accuracy, test_accuracy)\n",
    "    utils.plot_weights(fig, weights, '\\n'.join((title1, title2, title3)))\n",
    "    \n",
    "    # create a file name, append it to the filenames list\n",
    "    filename = '/'.join((outdir, f'frame_{epoch+1}.png'))\n",
    "    filenames.append(filename)\n",
    "    # and save the figure\n",
    "    fig.savefig(filename, facecolor=fig.get_facecolor())\n",
    "    plt.clf()\n",
    "\n",
    "    print(' '.join((title1, title2, title3)))\n",
    "\n",
    "    if simplification > 90.0 and test_accuracy > 98.0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a gif by composing the frames\n",
    "utils.images_to_gif(filenames, '/'.join((outdir, 'mnist_fc.gif')), tail=100)\n",
    "\n",
    "# create a mjpg video\n",
    "utils.images_to_avi(filenames, '/'.join((outdir, 'mnist_fc.avi')))\n",
    "\n",
    "# Remove frame files\n",
    "for filename in set(filenames):\n",
    "    os.remove(filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('3.9.2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "245dbc792dc39c3f0a9aacf957a37e7ff4bdace881e9e1e4748b1efe00e527b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
