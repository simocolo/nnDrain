{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from nndrain.tensor_edit import TensorEdit\n",
    "from nndrain.simplify_linear import SimplifyLinear\n",
    "import nndrain.utils as utils\n",
    "\n",
    "\n",
    "utils.set_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with SimplifyLinear modules\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc = nn.ModuleList()\n",
    "\n",
    "        # Iterate over each layer in hidden_size and create SimplifyLinear modules\n",
    "        for i_l in range(len(hidden_size)+1):\n",
    "            in_size = 0\n",
    "            out_size = 0\n",
    "            if i_l == 0:\n",
    "                # For the first layer, in_size is input_size and out_size is hidden_size[0]\n",
    "                in_size = input_size\n",
    "                out_size = hidden_size[0]\n",
    "                simplify_row = True\n",
    "                simplify_col = False\n",
    "                exclude_from_drain = True\n",
    "            elif i_l == len(hidden_size):\n",
    "                # For the last layer, in_size is hidden_size[-1] and out_size is output_size\n",
    "                in_size = hidden_size[-1]\n",
    "                out_size = output_size\n",
    "                simplify_row = False\n",
    "                simplify_col = True\n",
    "                exclude_from_drain = False\n",
    "            else:\n",
    "                # For all other layers, in_size is hidden_size[i_l-1] and out_size is hidden_size[i_l]\n",
    "                in_size = hidden_size[i_l-1]\n",
    "                out_size = hidden_size[i_l]\n",
    "                simplify_row = True\n",
    "                simplify_col = True\n",
    "                exclude_from_drain = False\n",
    "\n",
    "            # Create a SimplifyLinear module with the appropriate parameters\n",
    "            sl = SimplifyLinear(in_size, out_size, simplify_row, simplify_col, \n",
    "                                min_row=2, min_col=2, exclude_from_drain=exclude_from_drain)\n",
    "            self.fc.append(sl)\n",
    "            \n",
    "        self.apply(self._init_weights)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        \"\"\"\n",
    "        Initialize weights for a given module\n",
    "        \"\"\"\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Perform a forward pass through the neural network\n",
    "        \"\"\"\n",
    "        out = x\n",
    "        for i_l, l in enumerate(self.fc):\n",
    "            out = self.fc[i_l](out)\n",
    "            if i_l < len(self.fc)-1:\n",
    "                out = self.activation(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# XOR training data\n",
    "x = torch.Tensor([[0, 0],[0, 1], [1, 0], [1, 1]])\n",
    "y = torch.LongTensor([0, 1, 1, 0])\n",
    "\n",
    "# Define net parameters and model\n",
    "input_size = 2\n",
    "hidden_size = [150, 100, 50, 20]\n",
    "output_size = 2\n",
    "model = Net(input_size, hidden_size, output_size).to(device)\n",
    "n_start_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "epochs = 70000\n",
    "lr = 2e-2\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "figsize = (10, 4)\n",
    "outdir = 'out/xor'\n",
    "is_exist = os.path.exists(outdir)\n",
    "if not is_exist:\n",
    "    os.makedirs(outdir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig_weight = plt.figure(figsize=figsize, facecolor='white')\n",
    "filenames_weight = []\n",
    "filenames_network = []\n",
    "plot_epoch = 5\n",
    "increment = 2\n",
    "increment_limit = 1000\n",
    "increment_value = 1.5\n",
    "\n",
    "# Select the layers that can be simplified\n",
    "simplify_layers = [module for module in model.modules() if isinstance(module, SimplifyLinear)]\n",
    "te = TensorEdit(simplify_layers)\n",
    "\n",
    "drain_threshold_coeff = 3.0\n",
    "remove_threshold_coeff = 0.95\n",
    "\n",
    "# Initialize lists to store loss values and epoch numbers for plot\n",
    "loss_values = []\n",
    "epoch_values = []\n",
    "weight_values = []\n",
    "simplifications = []\n",
    "# frame counter\n",
    "idf = 0\n",
    "# Train the model\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    output = model.forward(x)\n",
    "    # Calculate loss\n",
    "    loss = loss_fun(output, y)\n",
    "    # Backpropagate and optimize\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "\n",
    "    te.set_threshold()\n",
    "    # Apply weights drain/decay to the model\n",
    "    te.weights_drain(p_drain=0.5, threshold_coeff=drain_threshold_coeff)\n",
    "    te.weights_decay(p_decay=0.5, decay_rate=5e-3)\n",
    "    # Remove weights if all values in a row or column are less than the specified value\n",
    "    if te.weights_remove(p_remove=0.5, threshold_coeff=remove_threshold_coeff, max_removal=1, verbose=True):\n",
    "        # Re-instantiate the optimizer with the new model if any rows or columns were deleted\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "   \n",
    "    # Plot weights and print progress every plot_every epochs or at the end of training\n",
    "    if epoch == plot_epoch or epoch + 1 == epochs:\n",
    "        plot_epoch += int(increment)\n",
    "        if increment < increment_limit:\n",
    "            increment += increment_value\n",
    "\n",
    "        epoch_values.append(epoch + 1)\n",
    "        # Append current loss value and epoch number to lists for plot\n",
    "        loss_values.append(loss.item())\n",
    "        \n",
    "        # Calculate simplification as (1 - actual_params / start_params) %\n",
    "        n_params = sum(p.numel() for p in model.parameters())\n",
    "        simplification = (1 - n_params / n_start_params) * 100\n",
    "        simplifications.append(simplification)\n",
    "\n",
    "        # Select weight matrices, transposing them for better visualization\n",
    "        weights = [w.weight.data.T for w in simplify_layers]\n",
    "        weight_values.append(weights)\n",
    "        \n",
    "        title1 = f\"XOR Example Epoch [{epoch+1}/{epochs}] Train Loss {loss.item():.4f} Params/StartParams: {n_params}/{n_start_params}\"\n",
    "        title2 = f\"Linear Layer Weights Simplification {simplification:.1f}%\"\n",
    "        ax_title = []\n",
    "        for i_w, w in enumerate(weights):\n",
    "            # Get minimum and maximum values for rows and columns in weight matrix\n",
    "            v_min_row, i_min_row = te.get_min_weight_row_threshold(w)\n",
    "            v_min_col, i_min_col = te.get_min_weight_col_threshold(w)\n",
    "            v_max_row, i_max_row = te.get_max_weight_row_threshold(w)\n",
    "            # Calculate remove threshold for current layer\n",
    "            layer_remove_threshold = remove_threshold_coeff * simplify_layers[i_w].threshold\n",
    "            # Create title for subplot with information about current layer\n",
    "            ax_title.append(f\"W{i_w}\\nthreshold {layer_remove_threshold:.4f}\\nrow_min {i_min_row},{v_min_row:.4f}\\ncol_min {i_min_col},{v_min_col:.4f}\\nmax {i_max_row},{v_max_row:.4f}\\n\")\n",
    "    \n",
    "        print(' '.join((title1, title2)))\n",
    "\n",
    "        # Plot weights and display progress\n",
    "        utils.plot_weights(fig_weight, weights, '\\n'.join((title1, title2)), ax_title=ax_title)\n",
    "        # Create file name and save figure\n",
    "        filename = '/'.join((outdir, f'frame_weight_{idf}.png'))\n",
    "        filenames_weight.append(filename)\n",
    "        fig_weight.savefig(filename, facecolor=fig_weight.get_facecolor())\n",
    "        idf += 1\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot neural network\n",
    "fig_network = plt.figure(figsize=figsize, facecolor='white')\n",
    "\n",
    "for idw, w in enumerate(weight_values):\n",
    "    # Pick a random input from the dataset\n",
    "    random_index = np.random.randint(len(x))\n",
    "    random_input = x[random_index]\n",
    "\n",
    "    # Forward the model with the random input\n",
    "    model_output = model(random_input)\n",
    "\n",
    "    # generate a list of input values and output values\n",
    "    input_list = [str(int(i.item())) for i in random_input]\n",
    "    output_list = [str(torch.argmax(model_output).item())]\n",
    "    \n",
    "    utils.plot_neural_network(fig_network, weights=w, title='', input_list=input_list, output_list=output_list, label_threshold=40)\n",
    "    # Create file name and save figure\n",
    "    filename = '/'.join((outdir, f'frame_network_{idw}.png'))\n",
    "    filenames_network.append(filename)\n",
    "    fig_network.savefig(filename, facecolor=fig_network.get_facecolor())\n",
    "    plt.clf()\n",
    "utils.images_to_gif(filenames_network, '/'.join((outdir, 'xor_net.gif')), tail=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_chart = plt.figure(figsize=figsize, facecolor='white')\n",
    "filenames_chart = []\n",
    "\n",
    "for ide, (e, s) in enumerate(zip(epoch_values, simplifications)):\n",
    "\n",
    "    utils.plot_charts(fig_chart, epochs=epoch_values[:ide+1], simplifications=simplifications[:ide+1])\n",
    "\n",
    "    # Create file name and save figure\n",
    "    filename = '/'.join((outdir, f'frame_chart_{ide}.png'))\n",
    "    filenames_chart.append(filename)\n",
    "    fig_chart.savefig(filename, facecolor=fig_chart.get_facecolor())\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "# Merge vertically the images for each frame\n",
    "for idf, (fw_name, fn_name, fc_name) in enumerate(zip(filenames_weight, filenames_network, filenames_chart)):\n",
    "    # Merge the images\n",
    "    result = utils.merge_images((fw_name, fn_name, fc_name))\n",
    "    \n",
    "    # Create file name and save figure\n",
    "    filename = '/'.join((outdir, f'frame_{idf}.png'))\n",
    "    filenames.append(filename)\n",
    "    result.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a gif by composing the frames\n",
    "utils.images_to_gif(filenames, '/'.join((outdir, 'xor_original.gif')), tail=100)\n",
    "\n",
    "# create a mjpg video\n",
    "utils.images_to_avi(filenames, '/'.join((outdir, 'xor.avi')))\n",
    "\n",
    "# Remove frame files\n",
    "for f in set(filenames_weight):\n",
    "    os.remove(f)\n",
    "for f in set(filenames_network):\n",
    "    os.remove(f)\n",
    "for f in set(filenames_chart):\n",
    "    os.remove(f)\n",
    "for f in set(filenames):\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Open the gif\n",
    "gif = Image.open('/'.join((outdir, 'xor_original.gif')))\n",
    "\n",
    "# Set the quality of the gif to 50\n",
    "gif.save('/'.join((outdir, 'xor.gif')), 'gif', save_all=True, optimize=True, quality=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all the remaining png files\n",
    "import glob\n",
    "\n",
    "for f in glob.glob(outdir + '/*.png'):\n",
    "    os.remove(f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "245dbc792dc39c3f0a9aacf957a37e7ff4bdace881e9e1e4748b1efe00e527b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('3.9.2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
