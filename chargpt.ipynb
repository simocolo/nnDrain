{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Trains a character-level language model.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from mingpt.model import GPT\n",
    "from mingpt.trainer import Trainer\n",
    "from mingpt.utils import set_seed, setup_logging, CfgNode as CN\n",
    "\n",
    "from nndrain.tensor_edit import TensorEdit\n",
    "from nndrain.simplify_linear import SimplifyLinear\n",
    "import nndrain.utils as utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Emits batches of characters\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def get_default_config():\n",
    "        C = CN()\n",
    "        C.block_size = 128\n",
    "        return C\n",
    "\n",
    "    def __init__(self, config, data):\n",
    "        self.config = config\n",
    "\n",
    "        chars = sorted(list(set(data)))\n",
    "        data_size, vocab_size = len(data), len(chars)\n",
    "        print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
    "\n",
    "        self.stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "        self.itos = { i:ch for i,ch in enumerate(chars) }\n",
    "        self.vocab_size = vocab_size\n",
    "        self.data = data\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        return self.vocab_size\n",
    "\n",
    "    def get_block_size(self):\n",
    "        return self.config.block_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.config.block_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # grab a chunk of (block_size + 1) characters from the data\n",
    "        chunk = self.data[idx:idx + self.config.block_size + 1]\n",
    "        # encode every character to an integer\n",
    "        dix = [self.stoi[s] for s in chunk]\n",
    "        # return as tensors\n",
    "        x = torch.tensor(dix[:-1], dtype=torch.long)\n",
    "        y = torch.tensor(dix[1:], dtype=torch.long)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config():\n",
    "\n",
    "    C = CN()\n",
    "\n",
    "    # system\n",
    "    C.system = CN()\n",
    "    C.system.seed = 3407\n",
    "    C.system.work_dir = './out/chargpt'\n",
    "\n",
    "    # data\n",
    "    C.data = CharDataset.get_default_config()\n",
    "\n",
    "    # model\n",
    "    C.model = GPT.get_default_config()\n",
    "    C.model.model_type = 'gpt-mini'\n",
    "\n",
    "    # trainer\n",
    "    C.trainer = Trainer.get_default_config()\n",
    "    C.trainer.num_workers = 0\n",
    "    C.trainer.learning_rate = 6e-4 # the model we're using is so small that we can go a bit faster\n",
    "    C.trainer.batch_size = 128\n",
    "    C.trainer.max_iters = 50000\n",
    "    return C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get default config and overrides from the command line, if any\n",
    "config = get_config()\n",
    "\n",
    "print(config)\n",
    "setup_logging(config)\n",
    "set_seed(config.system.seed)\n",
    "\n",
    "# construct the training dataset\n",
    "text = open('input.txt', 'r').read() # don't worry we won't run out of file handles\n",
    "train_dataset = CharDataset(config.data, text)\n",
    "\n",
    "# construct the model\n",
    "config.model.vocab_size = train_dataset.get_vocab_size()\n",
    "config.model.block_size = train_dataset.get_block_size()\n",
    "\n",
    "model = GPT(config.model)\n",
    "#ckpt_path = os.path.join(config.system.work_dir, \"model.pt\")\n",
    "#model = torch.load(ckpt_path)\n",
    "\n",
    "####################################\n",
    "n_start_params = sum(p.numel() for p in model.parameters())\n",
    "simplify_layers = [module for module in model.modules() if isinstance(module, SimplifyLinear)]\n",
    "te = TensorEdit(simplify_layers)\n",
    "fig, fig_chart = None, None\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(16, 10), facecolor='white')    \n",
    "filenames = []\n",
    "outdir = 'out/chargpt'\n",
    "####################################\n",
    "\n",
    "# construct the trainer object\n",
    "trainer = Trainer(config.trainer, model, train_dataset)\n",
    "\n",
    "# iteration callback\n",
    "def batch_end_callback(trainer):\n",
    "\n",
    "    epoch = int(trainer.iter_num/1) #define an arbitrary epoch just to periodically execute the underlying methods\n",
    "    te.weights_drain(p_drain=0.1, threshold_coeff=3.0, condition=epoch!=0 and epoch%5==0)\n",
    "    te.weights_decay(p_decay=0.1, decay_rate=5e-3, condition=epoch!=0 and epoch%3==0)\n",
    "\n",
    "    removed = False\n",
    "    if trainer.iter_num % 10 == 0:\n",
    "        print(f\"iter_dt {trainer.iter_dt * 1000:.2f}ms; iter {trainer.iter_num}: train loss {trainer.loss.item():.5f}\")\n",
    "        #for l in te.layers:\n",
    "        #    print(f\"Set threshold: {l.threshold}\")\n",
    "        # remove weights if all values ​​in a row or column are less than the specified value\n",
    "        if te.weights_remove(p_remove=1, threshold_coeff=0.1, max_removal=1.0, verbose=True):\n",
    "            # re-instantiate the optimizer with the new model if I have deleted any rows or columns\n",
    "            trainer.optimizer = model.configure_optimizers(config.trainer)\n",
    "\n",
    "    if trainer.iter_num % 100 == 0:\n",
    "\n",
    "        n_params = sum(p.numel() for p in model.parameters())\n",
    "        simplification = (1-n_params/n_start_params)*100\n",
    "        print(\"number of parameters: {:.3e} simplification: {:.1f}%\".format(n_params, simplification))\n",
    "\n",
    "        # plot\n",
    "        weights = [w.weight.data.T if w.weight.data.size()[1]>w.weight.data.size()[0] else w.weight.data for w in simplify_layers]\n",
    "\n",
    "        title1 = \"minGPT CharGPT Example Iter [{}/{}] Train Loss: {:.5f} Params/StartParams: {}/{}\"\\\n",
    "                    .format(trainer.iter_num, config.trainer.max_iters, trainer.loss.item(), n_params, n_start_params)\n",
    "        title2 = \"Linear Layer Weights Simplification: {:.1f}% Iter time: {:.2f}ms\"\\\n",
    "                    .format(simplification, trainer.iter_dt * 1000)\n",
    "\n",
    "        utils.plot_weights(fig, weights, '\\n'.join((title1, title2)))\n",
    "        \n",
    "        # create a file name, append it to the filenames list\n",
    "        filename = '/'.join((outdir, f'frame_{epoch+1}.png'))\n",
    "        filenames.append(filename)\n",
    "        # and save the figure\n",
    "        fig.savefig(filename, facecolor=fig.get_facecolor())\n",
    "        plt.clf()\n",
    "\n",
    "        # evaluate both the train and test score\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # sample from the model...\n",
    "            context = \"O God, O God!\"\n",
    "            x = torch.tensor([train_dataset.stoi[s] for s in context], dtype=torch.long)[None,...].to(trainer.device)\n",
    "            y = model.generate(x, 500, temperature=1.0, do_sample=True, top_k=10)[0]\n",
    "            completion = ''.join([train_dataset.itos[int(i)] for i in y])\n",
    "            print(completion)\n",
    "            \n",
    "        if trainer.iter_num>0:\n",
    "            # save the latest model\n",
    "            print(\"saving model\")\n",
    "            ckpt_path = os.path.join(config.system.work_dir, \"model.pt\")\n",
    "            torch.save(model, ckpt_path)\n",
    "        # revert model to training mode\n",
    "        model.train()\n",
    "\n",
    "trainer.set_callback('on_batch_end', batch_end_callback)\n",
    "\n",
    "# run the optimization\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a gif by composing the frames\n",
    "utils.images_to_gif(filenames, '/'.join((outdir, 'chargpt.gif')), tail=100)\n",
    "\n",
    "# create a mjpg video\n",
    "utils.images_to_avi(filenames, '/'.join((outdir, 'chargpt.avi')))\n",
    "\n",
    "# Remove frame files\n",
    "for filename in set(filenames):\n",
    "    os.remove(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('3.9.2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2 (default, Jun  8 2022, 09:46:46) \n[Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "245dbc792dc39c3f0a9aacf957a37e7ff4bdace881e9e1e4748b1efe00e527b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
